{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Forcing  2 AIs to Sing Still Alive From Portal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPoB16wtt8Lj",
        "colab_type": "text"
      },
      "source": [
        "# Forcing 2 AIs to Sing Still Alive From Portal\n",
        "\n",
        "By: [Jaden McElvey](https://twitter.com/JadenMcelvey)\n",
        "\n",
        "Last Updated: August 2020\n",
        "\n",
        "This notebook is intended to accompany my video on the 2009 puzzle platformer Portal. You can find the video explaining why I did this [here](https://youtu.be/QYBkCBUvu6w) and you can find my completed song [here](https://youtu.be/QvWH579lAPI).\n",
        "\n",
        "---\n",
        "\n",
        "Let's start off with the important stuff. I'm no expert on AI or machine learning or anything like that. I am but a lowly CS undergrad, so I got a lot of help from the internet and open source projects. If you're interested in seeing the work that helped me complete this project you should check the [References](#References) section at the end of this document. Throughout this notebook I'll use [$^{footnotes}$\n",
        "](#Footnotes) that link to the bottom of the notebook and explain how smart people choosing to share information made this possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNHVGT5l0Hp-",
        "colab_type": "text"
      },
      "source": [
        "## What Happened Here\n",
        "If your reading this its because you wanted a more in depth insight into what [this](https://) is and why/how it was made.\n",
        "### What?\n",
        "That video linked up there is a recreation of a song from a video game called Portal. In the game an artificial intelligence named GlaDOS sings you a song. I decided to teach a machine learning model to recreate this song. This did not go well.\n",
        "### Why?\n",
        "I make videos about why I think video games are art. My youtube channel is [here](https://www.youtube.com/channel/UCD9pjdMgEQ0YfKzNXcFZm9g/). Recently I decided to make a video about the beloved video game Portal, so I replayed the game and started working on a concept for a youtube video. The final video can be found [here](https://). I decided to make this video about music created by artificial intelligence. I then had the great(read time consuming) idea of remaking the iconic song *Still Alive*(which is sung in game by an AI) by training some machine learning models on the original music.\n",
        "### How?\n",
        "**WARNING INCREDIBLY NERDY INFO BELOW FEEL FREE TO SKIP THIS SECTION BECAUSE IT ISN'T CRUCIAL TO UNDERSTANDING THIS NOTEBOOK**\n",
        "\n",
        "The following is a list of tools used in this notebook that together will produce the final song.\n",
        "\n",
        "* [OpenAI's](https://openai.com/) [GPT-2](https://openai.com/blog/better-language-models/)**:** This is the machine learning model that will be used to generate the lyrics to the song\n",
        "* [Google's Magenta](https://magenta.tensorflow.org/)**:** This is a model trained on music that will be used to create a semi-original composition based on the music from *Still Alive*.\n",
        "* [gTTS](https://pypi.org/project/gTTS/)**:** This python library will allow us to convert text to speech for the final song\n",
        "* [Max Woolfs](https://minimaxir.com/) [aitextgen](https://github.com/minimaxir/aitextgen)**:** This is a tool created by Max Woolf that makes it easy for us to generate text with GPT-2\n",
        "* [FFmpeg](https://ffmpeg.org/)**:** This is a utility that will let us do a bit of audio processing later\n",
        "* [pydub](https://github.com/jiaaro/pydub)**:** This is a python library that allows us to combine and overlay audio segments(obviously super useful for making a song).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPDcCNNUEdNQ",
        "colab_type": "text"
      },
      "source": [
        "# Creating the Lyrics\n",
        "As previously stated we'll be using aitextgen to generate our lyrics. If you want more information on aitextgen see Max Woolf's notebook [aitextgen â€” Train a GPT-2 Text-Generating Model w/ GPU](https://colab.research.google.com/drive/15qBZx5y9rdaQSyWpsreMDnTiZ5IlN0zD?usp=sharing)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htw-_4-mExsB",
        "colab_type": "text"
      },
      "source": [
        "## Getting Training Data\n",
        "Ok, so we're trying to teach GPT-2 how to make new lyrics that are similar to the lyrics from *Still Alive* from portal. The first step here is to get all the lyrics to *Still Alive* so we can teach our model what the lyrics to this song are like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA6CZKwg4MTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import os\n",
        "# Create a folder named \"lyrics\" to contain all the vocal audio segments and lyric training data\n",
        "lyricFilePath = \"/content/lyrics\"\n",
        "if not os.path.exists(lyricFilePath):\n",
        "  try:\n",
        "      os.mkdir(lyricFilePath)\n",
        "  except OSError:\n",
        "      print (\"Creation of the directory %s failed\" % lyricFilePath)\n",
        "  else:\n",
        "      print (\"Successfully created the directory %s \" % lyricFilePath)\n",
        "\n",
        "# Get the text from my github repo that has our training data\n",
        "url = \"https://raw.githubusercontent.com/JadenMcElvey/AIs-Sing-Still-Alive-From-Portal/master/Songs.txt\"\n",
        "songText = requests.get(url)\n",
        "\n",
        "# Create a new file called Songs.txt and write the text to the file\n",
        "filePath = \"lyrics/Songs.txt\"\n",
        "file = open(filePath, \"w\")\n",
        "file.write(songText.text)\n",
        "file.close()\n",
        "shuffled = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oKe_iCa6474",
        "colab_type": "text"
      },
      "source": [
        "So if you actually look at that file that we just created called \"Songs.txt\" you'll notice that it has additional text that is not part of *Still Alive*. This additional text is from two other times that GlaDOS has sang in video games. GlaDOS sang Want You Gone in Portal 2 and You Wouldn't Know in LEGO Dimensions. This data is added because it gives our training data a little extra variety while still being relevant. Unfortunately having all of this data in the order that it is provided in the song would make the model write lyrics exactly as written in the song so we need even more variety in our data. This will be accomplished by shuffling all of the paragraphs and appending them to the end of the file.[$^{1}$](#Footnotes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osGDzgihBTe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "if not shuffled:\n",
        "  shuffled = True\n",
        "  # Read and shuffle the paragraphs from Songs.txt\n",
        "  with open(filePath, mode='r', encoding='utf-8') as f:\n",
        "          data = f.read()\n",
        "\n",
        "          # Split on \\n\\n\n",
        "          paragraphs = data.split('\\n\\n')\n",
        "\n",
        "          # Shuffle splits\n",
        "          random.shuffle(paragraphs)\n",
        "\n",
        "  # Append the paragraphs to the end of Songs.txt\n",
        "  with open(filePath,  mode='a', encoding='utf-8') as output:\n",
        "      output.write('\\n\\n')\n",
        "      for paragraph in paragraphs:\n",
        "          output.write(paragraph)\n",
        "\n",
        "          # Add the line break\n",
        "          output.write('\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD7p89E0EwrG",
        "colab_type": "text"
      },
      "source": [
        "## Finetuning the Model\n",
        "Now that we've got our data prepared we're ready to actually do some machine learning. First we're going to import/install everything we need to finetune a machine learning model. This next block of code also downloads the 124M GPT-2 model.[$^{2}$\n",
        "](#Footnotes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B8PiDcJxOnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze versions of dependencies for now\n",
        "!pip install transformers==2.9.1\n",
        "\n",
        "!pip install -q aitextgen\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "        format=\"%(asctime)s â€” %(levelname)s â€” %(name)s â€” %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO\n",
        "    )\n",
        "\n",
        "from aitextgen import aitextgen\n",
        "\n",
        "ai = aitextgen(tf_gpt2=\"124M\", to_gpu=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mw8muTxHAtd",
        "colab_type": "text"
      },
      "source": [
        "Next we train the model on the songs and wait. This may take 5-10 minutes to run. This model is being trained with relatively few steps because training it on with more steps pretty much guarantees that the model will be overfit. Every one hundred steps you can expect a sample of the text that the model has learned to generate. These samples should become more and more like *Still Alive* as the model trains."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6CJ22qrHCnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model on Songs.txt\n",
        "ai.train(file_name,\n",
        "         line_by_line=False,\n",
        "         from_cache=False,\n",
        "         num_steps=500,\n",
        "         generate_every=100,\n",
        "         save_every=100,\n",
        "         save_gdrive=False,\n",
        "         learning_rate=.00001,\n",
        "         batch_size=1, \n",
        "         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa5qvRXqMVFY",
        "colab_type": "text"
      },
      "source": [
        "Now that the ai knows what we want it to do we can ask it to write song lyrics for us. The following code will generate 5 samples of text at a time. They are being prompted with the phrase \"This was a triumph\" so that the ai knows to make something similar to *Still Alive*. Each sample should be approximately song length. For best results you should run the code below multiple times and pick your favorite lines. I did this when making my [video](https://).[$^{3}$\n",
        "](#Footnotes)\n",
        "\n",
        "**Important Note: GPT-2 is a general language processing model trained on text from the internet. It is likely that the model will say things you don't like that have nothing to do with portal songs. This is the nature of the model and can't really be helped.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xWO4iiyMmCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate 5 \"songs\"\n",
        "ai.generate(n=5,\n",
        "            batch_size=5,\n",
        "            prompt=\"This was a triumph.\",\n",
        "            max_length=350,\n",
        "            temperature=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U7yinRckguT",
        "colab_type": "text"
      },
      "source": [
        "## Singing the Lyrics\n",
        "Copy and paste the lyrics generated above into the string below. The first line of your lyrics should be on line 2.\n",
        "\n",
        "**Important Note: It's best if your lyrics are split up into paragraphs of no more than 20 lines. This improves the audio quality of the vocal track.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWreJzprklay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lyrics = \"\"\"\n",
        "This was a triumph.\n",
        "I'm making a note here:\n",
        "HUGE SUCCESS.\n",
        "It's hard to overstate\n",
        "My satisfaction.\n",
        "Aperture Science\n",
        "Aperture Science\n",
        "We don't need anyone now\n",
        "We find you. you get the point, you just leave\n",
        "You just keep on trying\n",
        "Till you run out of cake.\n",
        "\n",
        "This was a triumph.\n",
        "I'm making a note here It's your problem,\n",
        "It shows on your wrist It displays a certain amount of willpower\n",
        "When you're done you'll be gone\n",
        "And the Science you've got\n",
        "Is working.\n",
        "For the people who are\n",
        "Still alive.\n",
        "\n",
        "Well done, Yar, you're on your own.\n",
        "Now we're only a few things.\n",
        "Now we're making a new goal\n",
        "We'll reach our goal of reaching your body.\n",
        "So you're being given a substance that will make you sick\n",
        "Now we're making a new goal\n",
        "We'll reach your goal of reaching your body.\n",
        "Now we're releasing you.\n",
        "Now we're releasing you. you're dead.\n",
        "Let's go ahead and buy you a drink\n",
        "Now we're doing live science.\n",
        "We're testing your body. You'll be given a substance that will make you sick\n",
        "Think of all the things you've got\n",
        "For the better,\n",
        "Some will make you wish you had stayed,\n",
        "Others will make you wish you'd stayed,\n",
        "Still alive.\n",
        "\n",
        "We'll be releasing on time.\n",
        "So I'm GLaD. I got burned.\n",
        "Think of all the things we learned\n",
        "For the people who are\n",
        "HUGE thanks for the great jobs we're doing\n",
        "This was a triumph.\n",
        "I'm GLaD. I'm GLaD. I got burned.\n",
        "I don't need anyone now.\n",
        "We just keep on trying\n",
        "Til we run out of cake.\n",
        "And the Science gets done.\n",
        "And you make a neat gun.\n",
        "For the people who are\n",
        "powerful.\n",
        "And the people who are\n",
        "Still alive.\n",
        "\n",
        "This was a triumph.\n",
        "We will gladly take less of you.\n",
        "And cause your data to A) be Here\n",
        "And B) be at your Aperture Science Goodnight.\n",
        "As such, this design A) contains\n",
        "Is 'Cosmonautically' Allowed.\n",
        "It was tested and released.\n",
        "It worked.\n",
        "It worked as planned.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLrxuMEM42XD",
        "colab_type": "text"
      },
      "source": [
        "Now that we've got our beautifully totally coherent ai generated lyrics. we just need to convert lyrics to singing. The following code creates a new folder called lyrics and an mp3 file for each paragraph called #-0lyrics.mp3. You can download and listen to these if you want, but they still need some more audio processing before they sound like GlaDOS."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKkLCvQmiPZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gTTS\n",
        "from gtts import gTTS\n",
        "\n",
        "# Split the Lyrics into paragraphs\n",
        "lyricParagraphs = lyrics.split(\"\\n\\n\")\n",
        "\n",
        "# Use text to speech to create an audio file of every paragraph\n",
        "for i in range(len(lyricParagraphs)):\n",
        "  checkPath = \"/content/lyrics/{}-0lyric.mp3\".format(i)\n",
        "  if os.path.exists(checkPath):\n",
        "    os.remove(checkPath)\n",
        "\n",
        "  tts = gTTS(lyricParagraphs[i])\n",
        "  tts.save(lyricFilePath + \"/{}-0lyric.mp3\".format(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUTbazVT67DC",
        "colab_type": "text"
      },
      "source": [
        "So now that we've got each paragraph we need to make it sound like a robot. This is going to sound weird but the first step in making a robot voice is to create a second copy of the audio that is sped up by 0.1%. The following code creates a sped up version of each paragraph's audio file named #-1lyric.mp3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juEK-ztZ9F9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get all of the original text to speech audio files\n",
        "lyricFiles = os.listdir(\"/content/lyrics\")\n",
        "lyricFiles = [x for x in lyricFiles if x[2] == \"0\"]\n",
        "\n",
        "# Create a slightly sped up version of each audio file\n",
        "for inputFileName in lyricFiles:\n",
        "  outputFileName = \"lyrics/\" + inputFileName[:2] + \"1\" + inputFileName[3:]\n",
        "  inputFileName = \"lyrics/\" + inputFileName\n",
        "\n",
        "  checkPath = \"/content/\" + outputFileName\n",
        "  if os.path.exists(checkPath):\n",
        "    os.remove(checkPath)\n",
        "\n",
        "  !ffmpeg -hide_banner -loglevel panic -i {inputFileName} -filter:a \"atempo=1.001\" {outputFileName}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7GkdnikW-r4",
        "colab_type": "text"
      },
      "source": [
        "Next we just need to combine the original audio with the slighlty sped up audio to create the final robot vocal sounds. The following code creates a robot sounding version of each paragraph's audio file named #-2lyric.mp3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SVTGzcXZiBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pydub\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Create lists of all of the audio files\n",
        "lyricFiles = os.listdir(\"/content/lyrics\")\n",
        "lyricFiles0 = [\"/content/lyrics/\" + x for x in lyricFiles if x[2] == \"0\"]\n",
        "lyricFiles1 = [\"/content/lyrics/\" + x for x in lyricFiles if x[2] == \"1\"]\n",
        "lyricFiles0.sort()\n",
        "lyricFiles1.sort()\n",
        "\n",
        "# Combine the audio files together to make the audio sound more robot like\n",
        "for i in range(len(lyricFiles0)):\n",
        "  audio0 = AudioSegment.from_file(lyricFiles0[i])\n",
        "  audio1 = AudioSegment.from_file(lyricFiles1[i])\n",
        "  audio2 = audio0.overlay(audio1)\n",
        "\n",
        "  outputFileName = \"/content/lyrics/{}-2.lyric.mp3\".format(i)\n",
        "  audio2.export(outputFileName, format=\"mp3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mryi7REpNUlw",
        "colab_type": "text"
      },
      "source": [
        "Lastly we combine all of the audio files into one final complete vocal track."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_N_hJy6Pb5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a list of all of the robot like audio files\n",
        "lyricFiles = os.listdir(\"/content/lyrics\")\n",
        "lyricFiles2 = [\"/content/lyrics/\" + x for x in lyricFiles if x[2] == \"2\"]\n",
        "lyricFiles2.sort()\n",
        "\n",
        "# Combine the auido files together into one complete vocal track called vocalTrack.wav\n",
        "vocalTrack = AudioSegment.empty()\n",
        "for file in lyricFiles2:\n",
        "  vocalTrack += AudioSegment.from_file(file)\n",
        "  vocalTrack += AudioSegment.silent(duration=4000) \n",
        "\n",
        "vocalTrack.export(\"/content/vocalTrack.wav\", format=\"wav\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kouoc0mzgbpC",
        "colab_type": "text"
      },
      "source": [
        "We did it we've got a GlaDOS like voice singing our ai generated lyrics! Now on to generating the accompaniment!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYy6l5sREg82",
        "colab_type": "text"
      },
      "source": [
        "# Creating the Musical Accompaniment\n",
        "Now that we've got our vocal track complete we need to get some music to accompany our lovely robotic singing. We're going to generate the music using Google Magenta. Magenta is a project that lets us use machine learning to generate new melodies. Our melody is going to be based off of a midi file of Stay Alive. First lets download and install Magenta. If you want more information on using Magenta you should check out [Hello Magenta](https://colab.research.google.com/drive/1TiqYnRPWrgm_odG_6wdILEvK38L1Bqhx#scrollTo=7Y0VkNafNKLP).[$^{4}$\n",
        "](#Footnotes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDQyrac4_LNi",
        "colab_type": "text"
      },
      "source": [
        "## Setting up Magenta\n",
        "The following code may take a few minutes to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw69ZQiPMm5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "print('Installing dependencies...')\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -qU pyfluidsynth pretty_midi\n",
        "\n",
        "!pip install -qU magenta\n",
        "\n",
        "# Hack to allow python to pick up the newly-installed fluidsynth lib. \n",
        "# This is only needed for the hosted Colab environment.\n",
        "import ctypes.util\n",
        "orig_ctypes_util_find_library = ctypes.util.find_library\n",
        "def proxy_find_library(lib):\n",
        "  if lib == 'fluidsynth':\n",
        "    return 'libfluidsynth.so.1'\n",
        "  else:\n",
        "    return orig_ctypes_util_find_library(lib)\n",
        "ctypes.util.find_library = proxy_find_library\n",
        "\n",
        "print('Importing libraries and defining some helper functions...')\n",
        "from google.colab import files\n",
        "\n",
        "import magenta\n",
        "import note_seq\n",
        "import tensorflow\n",
        "\n",
        "print('ðŸŽ‰ Done!')\n",
        "print(magenta.__version__)\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9kKTigMSaLc",
        "colab_type": "text"
      },
      "source": [
        "Magenta is actually the name of a large project containing many different machine learning models that are capable of different music related tasks. For our purposes we'll use the basic MelodyRNN model to extrapolate our musical accompaniment. The code below initializes our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8AE_XeBSr-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a folder called music to store the music files\n",
        "musicFilePath = \"/content/music\"\n",
        "if not os.path.exists(musicFilePath):\n",
        "  try:\n",
        "      os.mkdir(musicFilePath)\n",
        "  except OSError:\n",
        "      print (\"Creation of the directory %s failed\" % musicFilePath)\n",
        "  else:\n",
        "      print (\"Successfully created the directory %s \" % musicFilePath)\n",
        "\n",
        "print('Downloading model bundle. This will take less than a minute...')\n",
        "note_seq.notebook_utils.download_bundle('basic_rnn.mag', '/content/music/')\n",
        "\n",
        "# Import dependencies.\n",
        "from magenta.models.melody_rnn import melody_rnn_sequence_generator\n",
        "from magenta.models.shared import sequence_generator_bundle\n",
        "from note_seq.protobuf import generator_pb2\n",
        "from note_seq.protobuf import music_pb2\n",
        "\n",
        "# Initialize the model.\n",
        "print(\"Initializing Melody RNN...\")\n",
        "bundle = sequence_generator_bundle.read_bundle_file('/content/music/basic_rnn.mag')\n",
        "generator_map = melody_rnn_sequence_generator.get_generator_map()\n",
        "melody_rnn = generator_map['basic_rnn'](checkpoint=None, bundle=bundle)\n",
        "melody_rnn.initialize()\n",
        "\n",
        "print('ðŸŽ‰ Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHS7IhLA_zfh",
        "colab_type": "text"
      },
      "source": [
        "## Generating Music\n",
        "The model still needs data to extrapolate our new melody from. For this purpose we'll use a midi version of *Still Alive*. The next code block downloads the song and converts it into a form that can be used by Magenta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL_rqdJqWw_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "# Download a midi file of Still Alive from my github\n",
        "url = \"https://github.com/JadenMcElvey/AIs-Sing-Still-Alive-From-Portal/blob/master/Still_Alive.mid?raw=true\"\n",
        "stillAliveMidi = requests.get(url)\n",
        "\n",
        "# Save the file in the music folder\n",
        "filePath = \"music/Still_Alive.mid\"\n",
        "file = open(filePath, \"wb\")\n",
        "file.write(stillAliveMidi.content)\n",
        "file.close()\n",
        "\n",
        "# Create a note sequence from the Still Alive midi and set the tempo to 120qpm\n",
        "stillAliveMidi = Path(\"/content/music/Still_Alive.mid\").read_bytes()\n",
        "stillAliveSeq = note_seq.midi_to_note_sequence(stillAliveMidi)\n",
        "del stillAliveSeq.tempos[:]\n",
        "stillAliveSeq.tempos.add(qpm=120)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORmQk95ZxJT1",
        "colab_type": "text"
      },
      "source": [
        "Now that we've got our source music its time to generate some new music. Below we calculate how long the new music should be, generate the music, and save our music as music/musicTrack.mid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKQZyFPmVj5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "# Tell the model to train on the Still Alive note sequence and set the temperature to 1.0\n",
        "input_sequence = stillAliveSeq\n",
        "temperature = 1.0\n",
        "\n",
        "# Set the start time to begin on the next step after the last note ends.\n",
        "last_end_time = (max(n.end_time for n in input_sequence.notes)\n",
        "                  if input_sequence.notes else 0)\n",
        "qpm = input_sequence.tempos[0].qpm\n",
        "seconds_per_step = 60.0 / qpm / melody_rnn.steps_per_quarter\n",
        "\n",
        "# Calculate the number of steps needed to generate music that matches the length of the vocal track\n",
        "seq_steps = (math.ceil(stillAliveSeq.total_time)) / seconds_per_step\n",
        "vocal_steps = math.ceil(len(vocalTrack) / 1000) / seconds_per_step\n",
        "num_steps = seq_steps + vocal_steps\n",
        "total_seconds = num_steps * seconds_per_step\n",
        "\n",
        "# Set generator options\n",
        "generator_options = generator_pb2.GeneratorOptions()\n",
        "generator_options.args['temperature'].float_value = temperature\n",
        "generate_section = generator_options.generate_sections.add(\n",
        "  start_time=last_end_time + seconds_per_step,\n",
        "  end_time=total_seconds)\n",
        "\n",
        "# Ask the model to continue the sequence.\n",
        "sequence = melody_rnn.generate(input_sequence, generator_options)\n",
        "\n",
        "# Trim the note sequence to only include the ai generated music\n",
        "sequence = note_seq.extract_subsequence(sequence, stillAliveSeq.total_time, sequence.total_time)\n",
        "\n",
        "# Play and save the ai generated music as musicTrack.mid in the music folder\n",
        "note_seq.plot_sequence(sequence)\n",
        "note_seq.play_sequence(sequence, synth=note_seq.fluidsynth)\n",
        "note_seq.sequence_proto_to_midi_file(sequence, \"music/musicTrack.mid\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCD_Q9NqWhpX",
        "colab_type": "text"
      },
      "source": [
        "And just like that our ai has generated original music. You can listen to it above if you're interested. Next we convert the music into a wav file for creating the final mix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KM5maqTV8uN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install fluidsynth and use fluidsynth to convert musicTrack to a wav file\n",
        "!apt install fluidsynth\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 music/font.sf2\n",
        "!fluidsynth -ni music/font.sf2 music/musicTrack.mid -F musicTrack.wav -r 32000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtFi962OV3RS",
        "colab_type": "text"
      },
      "source": [
        "# The Final Song\n",
        "We've got everything we need to put together our ai generated song, complete with vocals and accompaniment. Below we overlay the vocals over the music and apply a fade to the end of the song."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViPB__hdcBJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Open the the vocal and music tracks\n",
        "vocals = AudioSegment.from_wav(\"vocalTrack.wav\")\n",
        "music = AudioSegment.from_wav(\"musicTrack.wav\")\n",
        "\n",
        "# Increase the music volume and make the music fade out at the end\n",
        "musicAmplified = music.apply_gain(8)\n",
        "musicWithFade = musicAmplified.fade_out(4000)\n",
        "\n",
        "# Overlay the vocals over the music and save the final song as AI_Still_Alive.wav\n",
        "finalSong = musicWithFade.overlay(vocals)\n",
        "finalSong.export(\"AI_Still_Alive.wav\", format=\"wav\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE6MOIIJlETW",
        "colab_type": "text"
      },
      "source": [
        "You made it! Run the code below and press play to here your amazing new ai generated song. I'm sure your song has beautiful, coherent, meaningful lyrics and that your musical composition is a masterpiece."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EFkmbwNkpST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Listen to the final audio!\n",
        "from IPython.display import Audio\n",
        "Audio(\"AI_Still_Alive.wav\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJFd8a-CTxi1",
        "colab_type": "text"
      },
      "source": [
        "# Troubleshooting\n",
        "This notebook is best completed from start to finish if you encounter an error I would double check that you haven't skipped any the code blocks. If your issue persists I would recomment resetting the notebook. Reset the notebook at the top by clicking **Runtime > Factory Reset Runtime > Yes**. This will delete any lyrics you have saved so copy them somewhere else if you don't want to loose them. Good Luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOdlKTDGwFMc",
        "colab_type": "text"
      },
      "source": [
        "# References\n",
        "I'm not an expert on AI or machine learning or anything really, so I got help from these places.\n",
        "\n",
        "1. [How To Make Custom AI-Generated Text With GPT-2](https://minimaxir.com/2019/09/howto-gpt2/#:~:text=Speaking%20of%20generation%2C%20once%20you,By%20default%2C%20the%20gpt2.&text=You%20can%20download%20the%20generated,and%20share%20the%20generated%20texts.)\n",
        "2. [aitextgen github](https://github.com/minimaxir/aitextgen)\n",
        "3. [aitextgen â€” Train a GPT-2 Text-Generating Model w/ GPU Colab Notebook](https://colab.research.google.com/drive/15qBZx5y9rdaQSyWpsreMDnTiZ5IlN0zD?usp=sharing)\n",
        "4. [How to build and deploy a lyrics generation model â€” framework agnostic](https://towardsdatascience.com/how-to-build-and-deploy-a-lyrics-generation-model-framework-agnostic-589f3026fd53)\n",
        "5. [Hello Magenta](https://colab.research.google.com/notebooks/magenta/hello_magenta/hello_magenta.ipynb#scrollTo=dPkdg9jTjkTd)\n",
        "6. [Magenta Github](https://github.com/magenta)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtR15uwBF1gJ",
        "colab_type": "text"
      },
      "source": [
        "# Footnotes\n",
        "1. Originally I was shuffling each line instead of shuffling each paragraph. This in fact, was a bad idea and the model produced results that weren't organized into paragraphs anymore. [This](https://towardsdatascience.com/how-to-build-and-deploy-a-lyrics-generation-model-framework-agnostic-589f3026fd53) project gave me the idea of shuffling based on paragraphs. It also gave me the idea of shuffling with a script instead of shuffling manually. I know how to write code I just forgot that solving my problems with code was better than solving stuff by hand. I also used a script from this article to shuffle the paragraphs.\n",
        "2. This section on generating lyrics is almost identical to Woolf's original notebook. Some parameters have been tweaked and unnecessary bits of code have been removed but otherwise its the same content. You really should give the [original notebook](https://colab.research.google.com/drive/15qBZx5y9rdaQSyWpsreMDnTiZ5IlN0zD?usp=sharing) a look.\n",
        "3. In the interest of full transparency it should be noted that the lyrics from my [video](https://) are curated. I spent approximately 2 hours generating different lyrics and chose the best paragraphs to create my song. This is how I got my lyrics to mirror the structure of the original song. It is important to remember that given the model configuration in this notebook it is **not** possible(or at least highly improbable) to generate lyrics that closely match the structure of the original song. The lyrics for my video are heavily curated.\n",
        "4. If you want a real tutorial on Magenta you should at least read through [Hello Magenta](https://colab.research.google.com/drive/1TiqYnRPWrgm_odG_6wdILEvK38L1Bqhx#scrollTo=7Y0VkNafNKLP). This is where I learned to use Magenta. Most of the code from this section is from that notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mffQsnSJeBEL",
        "colab_type": "text"
      },
      "source": [
        "# License\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2020 Jaden McElvey\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}